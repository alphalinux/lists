<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN"> 
     <HTML> 
     <HEAD> 
     <TITLE>Axp-List Archive</TITLE> 
     <LINK REV="made" HREF="mailto:mailto-address"> 
     <HEAD> 
     <BODY BGCOLOR="#DC9D33" TEXT="#000000" LINK="#DD0000" ALINK="#CC0000" VLINK="#CC0000">
		<CENTER>  <!--#exec cgi="/cgi-bin/banmat1.cgi"--></CENTER>

     <H1 ALIGN=CENTER>Axp-List Archive<BR> Re: SBC Alphas</H1> 
	
<!-- received="Mon Nov 20 05:23:11 2000" -->
<!-- isoreceived="20001120132311" -->
<!-- sent="Sun, 19 Nov 2000 01:37:02 -0600" -->
<!-- isosent="20001119073702" -->
<!-- name="W Bauske" -->
<!-- email="wsb@paralleldata.com" -->
<!-- subject="Re: SBC Alphas" -->
<!-- id="3A17831E.7FFA0775@paralleldata.com" -->
<!-- inreplyto="3A177517.DD9D312C@bravegnuworld.com" -->
<STRONG>Subject: </STRONG>Re: SBC Alphas<BR>
<STRONG>From: </STRONG>W Bauske (<EM>wsb@paralleldata.com</EM>)<BR>
<STRONG>Date: </STRONG>Sat Nov 18 23:37:02 2000
<P>
<UL>
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.shtml#393">[ date ]</A>
<A HREF="index.shtml#393">[ thread ]</A>
<A HREF="subject.shtml#393">[ subject ]</A>
<A HREF="author.shtml#393">[ author ]</A>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="0394.shtml">Dave Gilbert: "Re: SBC Alphas"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0392.shtml">Richard June: "Re: SBC Alphas"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="0392.shtml">Richard June: "Re: SBC Alphas"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0394.shtml">Dave Gilbert: "Re: SBC Alphas"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="0392.shtml">W Bauske: "Re: SBC Alphas"</A>
<!-- reply="end" -->
</UL>
<HR>
<!-- body="start" -->
<P>
Richard June wrote:
<BR>
<EM>&gt; 
</EM><BR>
<EM>&gt; W Bauske wrote:
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Richard June wrote:
</EM><BR>
<EM>&gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; Maurice Hilarius wrote:
</EM><BR>
<EM>&gt; &gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; &gt; With regards to your message at 07:39 PM 11/17/00, Mike Tibor. Where you
</EM><BR>
<EM>&gt; &gt; &gt; &gt; stated:
</EM><BR>
<EM>&gt; &gt; &gt; &gt; &gt;I've never heard anything related to clusters and single board computers,
</EM><BR>
<EM>&gt; &gt; &gt; &gt; &gt;but on the surface it seems like something like this might be pretty good
</EM><BR>
<EM>&gt; &gt; &gt; &gt; &gt;in building a cluster:
</EM><BR>
<EM>&gt; &gt; &gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; &gt; &gt;<A HREF="http://cgi.ebay.com/aw-cgi/eBayISAPI.dll?ViewItem&item=499466745">http://cgi.ebay.com/aw-cgi/eBayISAPI.dll?ViewItem&item=499466745</A>
</EM><BR>
<EM>&gt; &gt; &gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; &gt; &gt;Those of you who've done clusters, what do you think?
</EM><BR>
<EM>&gt; &gt; &gt; &gt; Expensive bus, weird cards, strange power.
</EM><BR>
<EM>&gt; &gt; &gt; &gt; Expensive to implement.
</EM><BR>
<EM>&gt; &gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt; &gt; Maybe so, but it's convienient to have 10 or so PCI slots in a machine.
</EM><BR>
<EM>&gt; &gt; &gt; and PicMG with a backplane is the only way I've seen that done.
</EM><BR>
<EM>&gt; &gt; &gt;
</EM><BR>
<EM>&gt; &gt;
</EM><BR>
<EM>&gt; &gt; Pretty much all the SBC stuff I've seen is not cost effective
</EM><BR>
<EM>&gt; &gt; compared to commodity parts. If you need more slots, buy two
</EM><BR>
<EM>&gt; &gt; standard systems and network them. What are you doing that
</EM><BR>
<EM>&gt; &gt; requires lots of slots that multiple systems wouldn't solve?
</EM><BR>
<EM>&gt; &gt; Just curious.
</EM><BR>
<EM>&gt; Routers.
</EM><BR>
<EM>&gt; Where I work we build routers, a single system with 10 slots is easier
</EM><BR>
<EM>&gt; to deal with then two routers networked, plus you don't have to use that
</EM><BR>
<EM>&gt; bus bandwidth.
</EM><BR>
<EM>&gt; 
</EM><BR>
<P>OK. I see that. But don't routers need other things like
<BR>
hot swap slots for cards and failover/redundancy, etc.? 
<BR>
They're more complicated than a node for a cluster needs
<BR>
to be. 
<BR>
<P>Some cards have built-in bridges to allow more effective
<BR>
slots too, like those 4 way tulip cards or multi-channel
<BR>
SCSI cards so it's actually using single cards that makes
<BR>
the large number of slots preferable.
<BR>
<P>Now, if there are backplanes that allow, say 8 dual cpu
<BR>
SBC's, suitable for a 4U cabinet, that might make an
<BR>
interesting node for building clusters.
<BR>
<P><P>Wes
<BR>
<P><P><P>_______________________________________________
<BR>
Axp-list mailing list
<BR>
Axp-list@redhat.com
<BR>
https://listman.redhat.com/mailman/listinfo/axp-list
<BR>
<P><!-- body="end" -->
<HR>
<P>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="0394.shtml">Dave Gilbert: "Re: SBC Alphas"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="0392.shtml">Richard June: "Re: SBC Alphas"</A>
<LI><STRONG>In reply to:</STRONG> <A HREF="0392.shtml">Richard June: "Re: SBC Alphas"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0394.shtml">Dave Gilbert: "Re: SBC Alphas"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="0392.shtml">W Bauske: "Re: SBC Alphas"</A>
<!-- reply="end" -->
</UL>
<!-- trailer="footer" -->
<HR> 
     <P> 
     <SMALL> 
     <EM> 
     This archive was generated by  <A HREF="http://www.landfield.com/hypermail">hypermail version 2a22 </A> on Fri Dec  1 08:00:08 2000 PST <BR>
	Send any problems or questions about this archive to <A HREF="mailto:webmaster@alphalinux.org">webmaster@alphalinux.org</A>. 
     </EM> 
     </SMALL> 
     </BODY> 
     </HTML> 
