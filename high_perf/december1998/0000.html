<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<HTML>
<HEAD>
<TITLE>High Performance Alpha Linux: Re: Questions on performance meth</TITLE>
<META NAME="Author" CONTENT="naohiko shimizu (nshimizu@et.u-tokai.ac.jp)">
<META NAME="Subject" CONTENT="Re: Questions on performance methods">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1 ALIGN=CENTER>Re: Questions on performance methods</H1>
<HR>
<P>
<!-- received="Thu Jan 21 21:41:33 1999 EST" -->
<!-- sent="Tue, 1 Dec 1998 15:24:27 +0900 (JST)" -->
<!-- name="naohiko shimizu" -->
<!-- email="nshimizu@et.u-tokai.ac.jp" -->
<!-- subject="Re: Questions on performance methods" -->
<!-- id="199812010624.PAA02425@et.u-tokai.ac.jp" -->
<!-- inreplyto="199811300254.LAA26438@et.u-tokai.ac.jp" -->
<STRONG>naohiko shimizu</STRONG> (<A HREF="mailto:nshimizu@et.u-tokai.ac.jp?subject=Re:%20Questions%20on%20performance%20methods"><EM>nshimizu@et.u-tokai.ac.jp</EM></A>)<BR>
<EM>Tue, 1 Dec 1998 15:24:27 +0900 (JST)</EM>
<P>
<UL>
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#0">[ date ]</A>
<A HREF="index.html#0">[ thread ]</A>
<A HREF="subject.html#0">[ subject ]</A>
<A HREF="author.html#0">[ author ]</A>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="0001.html">Joachim Wesner: "Re: how to optimize dgemm? No.1"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0003.html">Joachim Wesner: "Re: Questions on performance methods"</A>
</UL>
<HR>
<!-- body="start" -->
<P>
In article &lt;<A HREF="mailto:9811301409.AA28540@liszt.amt.tay1.dec.com?subject=Re:%20Questions%20on%20performance%20methods">9811301409.AA28540@liszt.amt.tay1.dec.com</A>&gt;
<BR>
<A HREF="mailto:gorton@amt.tay1.dec.com?subject=Re:%20Questions%20on%20performance%20methods">gorton@amt.tay1.dec.com</A> writes:
<BR>
<P><EM>&gt;&gt; 
</EM><BR>
<EM>&gt;&gt; Naohiko Shimizu wrote:
</EM><BR>
<EM>&gt;&gt; 
</EM><BR>
<EM>&gt;&gt; &gt;But I myself is not comfortable with 21264, because it does not
</EM><BR>
<EM>&gt;&gt; &gt;improve the peak floating point performance from 21164. The 21364
</EM><BR>
<EM>&gt;&gt; &gt;will use the same core with 21264 and then we cannot expect
</EM><BR>
<EM>&gt;&gt; &gt;outperformed performance with these chips.
</EM><BR>
<EM>&gt;&gt; 
</EM><BR>
<EM>&gt;&gt; If by 'peak floating point performance' you mean &quot;number of floating
</EM><BR>
<EM>&gt;&gt; point instructions issued/cycle&quot; then this is a correct statement.
</EM><BR>
<EM>&gt;&gt; 
</EM><BR>
<EM>&gt;&gt; However, since it is an out-of-order machine, the actual elapsed time
</EM><BR>
<EM>&gt;&gt; to complete a job can be significantly less on a 21264 machine than on
</EM><BR>
<EM>&gt;&gt; a 21164 machine with the same clock rate.
</EM><BR>
<EM>&gt;&gt; 
</EM><BR>
<P>Rick, if you feel that my post was miss leading for general users,
<BR>
please excuse me. As I wrote, we can retrieve full power of
<BR>
21264 with higher level languages and it will be very nice for general.
<BR>
The chip is well designed, I think. But I wonder that if 21164A uses
<BR>
same process rule, it will mark higher clock rating. And the easy 
<BR>
optimizable routine may have higher performance with (enhanced) 21164A.
<BR>
<P><EM>&gt;&gt; Additionally, the number of cycles to execute some FP operations is
</EM><BR>
<EM>&gt;&gt; significantly better on the 21264 vs. the 21164 (i.e. divide)
</EM><BR>
<EM>&gt;&gt; The addition of instructions in the architecture to perform SQRT
</EM><BR>
<EM>&gt;&gt; (among other items) will result in additional performance gains.
</EM><BR>
<P>I think multiply-accumulate type instruction is usefull for many
<BR>
applicatoins, wouldn't you disscussed to include such instructions?
<BR>
<P>In article &lt;<A HREF="mailto:19981130095516.B4303@keksy.mchp.siemens.de?subject=Re:%20Questions%20on%20performance%20methods">19981130095516.B4303@keksy.mchp.siemens.de</A>&gt;
<BR>
<A HREF="mailto:martin.kahlert@mchp.siemens.de?subject=Re:%20Questions%20on%20performance%20methods">martin.kahlert@mchp.siemens.de</A> writes:
<BR>
<P><EM>&gt;&gt; Is it very stupid to ask what TLB and MAF means?
</EM><BR>
<EM>&gt;&gt; Sorry, to aks that silly questions.
</EM><BR>
<P>TLB is reffered as DTB in the Digital documentations. It is a data 
<BR>
address translation buffer to support virtual addressing, 
<BR>
and no load can be issued behind DTB miss. Because, if DTB miss
<BR>
occured the processor must check page table in the main memory to decide
<BR>
whether an page fault interrupt may or may not be occured. The interrupt must
<BR>
be precise and all instructions issued behind the load must be cancelled.
<BR>
Then shortage of DTB cause performance degradation. I think 21164A could
<BR>
have 1024 two way DTB with a few victim entries, instead of full associative
<BR>
64 entries DTB.
<BR>
<P>The combination of Miss Address File(MAF) and pipelined Scache(L2 cache)
<BR>
is the key point to get higher performance with 21164(A).
<BR>
I will explain a little more:
<BR>
<P>21164(A) is not an out-of-order processor, but only the load instruction
<BR>
can be treated as out-of-order with MAF.
<BR>
There are 5 MAF in 21164(A), and each can hold a cache miss load address.
<BR>
Then we can issue 5 independent address load which does not hit the cache
<BR>
without stall. And four of them can have upto four miss load which share
<BR>
the same cache line. So we can issue upto 21 miss load without stall.
<BR>
Additionaly, Scache can handle L2-&gt;L1 cache block transfer as a pipeline.
<BR>
The latency of Scache is 12 cycles, and if the loop is longer than 12, 
<BR>
the code will not stall for cache miss as far as Scache hit.
<BR>
If Scache miss is occured, only two outstanding loads is allowed.
<BR>
(21164PC can issue three outstanding loads, and 21264 will have eight.)
<BR>
Then we need to control where the outstanding loads will be placed.
<BR>
The basics are the same for 21264, and carefully designed program will
<BR>
mark higher performance even for out-of-order processors.
<BR>
BTW, when will the hardware refference manual for 21264 will be released?
<BR>
<P>Typical high performance programs for 21164(A) can be organized
<BR>
as following. 
<BR>
21164(A) can issue two load per cycle, and this code is software pipelined. 
<BR>
<P>foo:
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load A[i+0]      load A[i+1]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load A[i+2]      load A[i+3]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load B[i+0]      load B[i+1]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load B[i+2]      load B[i+3]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load C[i+0]      load C[i+1]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load C[i+2]      load C[i+3]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load D[i+0]      load D[i+1]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load D[i+2]      load D[i+3]
<BR>
loop:
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;execute something with A,B,C,D
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load A[i+4]      load A[i+5]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load A[i+6]      load A[i+7]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load B[i+4]      load B[i+5]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load B[i+6]      load B[i+7]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load C[i+4]      load C[i+5]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load C[i+6]      load C[i+7]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load D[i+4]      load D[i+5]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;load D[i+6]      load D[i+7]
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;update i by 4
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;goto loop
<BR>
<P><P>In article &lt;<A HREF="mailto:199811300254.LAA26438@et.u-tokai.ac.jp?subject=Re:%20Questions%20on%20performance%20methods">199811300254.LAA26438@et.u-tokai.ac.jp</A>&gt;
<BR>
<A HREF="mailto:nshimizu@et.u-tokai.ac.jp?subject=Re:%20Questions%20on%20performance%20methods">nshimizu@et.u-tokai.ac.jp</A> writes:
<BR>
<P><EM>&gt;&gt; If the N is large (N &gt; 10000), the code I and Goto wrote will use too much
</EM><BR>
<EM>&gt;&gt; memory traffic.  Then we still have a chance to improve the 
</EM><BR>
<EM>&gt;&gt; performance with blocking.  Last night it was almost 3am in localtime 
</EM><BR>
<EM>&gt;&gt; when I read the mail, and I had not enough time to code.
</EM><BR>
<EM>&gt;&gt; 
</EM><BR>
<P>I tune the code with prefetching and code optimization. 
<BR>
This may be my final for this problem.
<BR>
The q[] should have at least additional 9 dummy entiries for prefetching.
<BR>
Use gcc/egcs to compile the code.(still not debuged)
<BR>
<P>----------------------------------------------------------------------------
<BR>
#define BLOCKINGSIZE 1000
<BR>
#define prefetch(x) asm volatile (&quot;ldt $f31,%0&quot; :: &quot;m&quot;((x)))
<BR>
<P>void dsqrtiv(double *, double *, int);
<BR>
<P>double find_jastrow_sub(double *vtemp, double b, int count) {
<BR>
&nbsp;&nbsp;int i;
<BR>
&nbsp;&nbsp;double tmp0,tmp1,tmp2,tmp3,tmp4,tmp5,tmp6,tmp7;
<BR>
&nbsp;&nbsp;double vtmp[8];
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;dsqrtiv(vtemp, vtemp, count);
<BR>
<P>/*
<BR>
Unrolling and software pipelining the loop. 
<BR>
8 times unrolling is enough for the Scache pipeline.
<BR>
*/
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;i = 0;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;tmp0 = tmp1 = tmp2 = tmp3 = 
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;tmp4 = tmp5 = tmp6 = tmp7 = 1.0;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;vtmp[0] =  vtemp[i];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;vtmp[1] =  vtemp[i+1];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;vtmp[2] =  vtemp[i+2];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;vtmp[3] =  vtemp[i+3];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;vtmp[4] =  vtemp[i+4];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;vtmp[5] =  vtemp[i+5];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;vtmp[6] =  vtemp[i+6];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;vtmp[7] =  vtemp[i+7];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;for(i=0;i &lt; count-8; i+=8){
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp0 *= (1.0 - b * vtmp[0]);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp1 *= (1.0 - b * vtmp[1]);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp2 *= (1.0 - b * vtmp[2]);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp3 *= (1.0 - b * vtmp[3]);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp4 *= (1.0 - b * vtmp[4]);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp5 *= (1.0 - b * vtmp[5]);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp6 *= (1.0 - b * vtmp[6]);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp7 *= (1.0 - b * vtmp[7]);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vtmp[0] =  vtemp[i+8];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vtmp[1] =  vtemp[i+9];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vtmp[2] =  vtemp[i+10];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vtmp[3] =  vtemp[i+11];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vtmp[4] =  vtemp[i+12];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vtmp[5] =  vtemp[i+13];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vtmp[6] =  vtemp[i+14];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vtmp[7] =  vtemp[i+15];
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;}
<BR>
/*
<BR>
The rest of the loop will be here.
<BR>
*/
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;for(i=0;i &lt; count - i;i++)
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp0 *= (1.0 - b * vtmp[i]);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;return tmp0*tmp1*tmp2*tmp3*tmp4*tmp5*tmp6*tmp7;
<BR>
&nbsp;&nbsp;}
<BR>
<P><P>int find_jastrow(double *result,int j,struct coord *q,double r[3],double b){
<BR>
<P>&nbsp;&nbsp;int i,vcnt;
<BR>
&nbsp;&nbsp;double tmp, tmp1, tmp2, tmp3;
<BR>
&nbsp;&nbsp;double t1, t2, t3;
<BR>
&nbsp;&nbsp;double r1, r2, r3;
<BR>
&nbsp;&nbsp;double bp2;
<BR>
&nbsp;&nbsp;double vtemp[BLOCKINGSIZE+16];
<BR>
<P>&nbsp;&nbsp;r1 = r[0];
<BR>
&nbsp;&nbsp;r2 = r[1];
<BR>
&nbsp;&nbsp;r3 = r[2];
<BR>
&nbsp;&nbsp;
<BR>
&nbsp;&nbsp;tmp  =  1.0;
<BR>
<P>&nbsp;&nbsp;vcnt = 0;
<BR>
&nbsp;&nbsp;bp2 = b*b;
<BR>
<P>&nbsp;&nbsp;if(b&gt;0){
<BR>
/*
<BR>
&nbsp;To reduce inner loop conditional branch, I separate the loop.
<BR>
&nbsp;This may not be required if the compiler is smart enough.
<BR>
&nbsp;When b**2 &lt; rij, we should return immediately, without calling sqrt.
<BR>
&nbsp;Then I add one conditional branch *_*.
<BR>
*/
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;i = 0;
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;tmp1 = q[i].x[0]-r1;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;tmp2 = q[i].x[1]-r2;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;tmp3 = q[i].x[2]-r3;
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;for(i=0;i &lt; j;i++){
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t1 = tmp1*tmp1;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t2 = tmp2*tmp2;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t3 = tmp3*tmp3;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp1 = q[i+1].x[0]-r1;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp2 = q[i+1].x[1]-r2;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp3 = q[i+1].x[2]-r3;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prefetch(q[i+9].x[0]);
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if((vtemp[vcnt++] = t1 + t2 + t3) &gt; bp2) {
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*result = 0.0;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return 0;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(vcnt &gt;= BLOCKINGSIZE) {
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp *= find_jastrow_sub(vtemp, b, vcnt);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vcnt = 0;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;tmp1 = q[j+1].x[0]-r1;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;tmp2 = q[j+1].x[1]-r2;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;tmp3 = q[j+1].x[2]-r3;
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;for(i=j+1;i &lt; N;i++){
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t1 = tmp1*tmp1;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t2 = tmp2*tmp2;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t3 = tmp3*tmp3;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp1 = q[i+1].x[0]-r1;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp2 = q[i+1].x[1]-r2;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp3 = q[i+1].x[2]-r3;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prefetch(q[i+9].x[0]);
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if((vtemp[vcnt++] = t1 + t2 + t3) &gt; bp2) {
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*result = 0.0;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return 0;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(vcnt &gt;= BLOCKINGSIZE) {
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmp *= find_jastrow_sub(vtemp, b, vcnt);
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vcnt = 0;
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;tmp *= find_jastrow_sub(vtemp, b, vcnt);
<BR>
&nbsp;&nbsp;}
<BR>
&nbsp;&nbsp;*result = tmp;
<BR>
&nbsp;&nbsp;return 1;
<BR>
}
<BR>
<P><P>Naohiko Shimizu
<BR>
Dept. Communication Engr./Univ. TOKAI.
<BR>
1117 Kitakaname Hiratsuka 259-12 Japan
<BR>
TEL.+81-463-58-1211(ext. 4084) FAX.+81-463-58-8320
<BR>
&lt;URL <A HREF="http://shimizu-lab.et.u-tokai.ac.jp/">http://shimizu-lab.et.u-tokai.ac.jp/</A>&gt;
<BR>
<P><!-- body="end" -->
<HR>
<P>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="0001.html">Joachim Wesner: "Re: how to optimize dgemm? No.1"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="0003.html">Joachim Wesner: "Re: Questions on performance methods"</A>
</UL>
<!-- trailer="footer" -->
<HR>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.landfield.com/hypermail/">hypermail 2.0b3</A> 
on <EM>Thu Jan 21 1999 - 21:41:39 EST</EM>
</EM>
</SMALL>
</BODY>
</HTML>
